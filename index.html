<!DOCTYPE html>
<html lang="he">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>×”×¢×•×–×¨ ×”×—×›× ×©×œ ×’×™×</title>
  <link href="https://fonts.googleapis.com/css2?family=Varela+Round&display=swap" rel="stylesheet">
  <script src="https://cdn.jsdelivr.net/npm/pdfjs-dist@2.16.105/build/pdf.min.js"></script>
  <style>
    body {
      font-family: 'Varela Round', sans-serif;
      background: linear-gradient(to bottom, #2b0000, #4a0000, #000000);
      color: white;
      text-align: center;
      padding: 2rem;
      direction: rtl;
    }
    h1 {
      font-size: 3rem;
      color: #ff4d4d;
      margin-bottom: 0.5rem;
    }
    .icon {
      font-size: 2.5rem;
      vertical-align: middle;
      margin-left: 0.5rem;
    }
    input[type="file"], input[type="text"], button {
      margin: 0.7rem;
      padding: 0.8rem 1.2rem;
      border-radius: 1rem;
      border: none;
      font-size: 1rem;
    }
    input[type="text"] {
      width: 60%;
    }
    #recordButton {
      background: linear-gradient(45deg, #ff0000, #ff4d4d);
      color: white;
      font-weight: bold;
      cursor: pointer;
    }
    #recordButton.recording {
      animation: pulse 1s infinite;
      background: darkred;
    }
    @keyframes pulse {
      0% { transform: scale(1); }
      50% { transform: scale(1.1); }
      100% { transform: scale(1); }
    }
    button:hover {
      opacity: 0.85;
    }
    #response {
      margin-top: 2rem;
      padding: 1rem;
      background: rgba(255, 255, 255, 0.08);
      border-radius: 1rem;
      font-size: 1.2rem;
      max-width: 800px;
      margin-inline: auto;
    }
    audio {
      margin-top: 1rem;
    }
  </style>
</head>
<body>
  <h1><span class="icon">ğŸ§ </span>×”×¢×•×–×¨ ×”×—×›× ×©×œ ×’×™×</h1>

  <input type="file" id="pdfUpload" accept="application/pdf" />
  <br>
  <button id="recordButton">ğŸ™ï¸ ×œ×—×¥ ×•×“×‘×¨</button>
  <br>
  <input type="text" id="userInput" placeholder="×©××œ ×©××œ×” ×‘×¢×‘×¨×™×ª ××• ×× ×’×œ×™×ª" />
  <button onclick="askAgent()">×©××œ ××ª ×’×™×</button>

  <div id="response">ğŸ’¬ ×”×”×•×“×¢×•×ª ×™×•×¦×’×• ×›××Ÿ</div>

  <!-- ğŸµ ××•×–×™×§×” -->
  <audio autoplay loop controls>
    <source src="https://www.bensound.com/bensound-music/bensound-dubstep.mp3" type="audio/mpeg">
    ×”×“×¤×“×¤×Ÿ ×©×œ×š ×œ× ×ª×•××š ×‘× ×™×’×•×Ÿ ××•×“×™×•.
  </audio>

  <script>
    let pdfText = "";
    let isRecording = false;

    document.getElementById('pdfUpload').addEventListener('change', async function (e) {
      const file = e.target.files[0];
      if (file) {
        const reader = new FileReader();
        reader.onload = async function () {
          const typedarray = new Uint8Array(this.result);
          const pdf = await pdfjsLib.getDocument(typedarray).promise;
          let fullText = '';
          for (let i = 1; i <= pdf.numPages; i++) {
            const page = await pdf.getPage(i);
            const content = await page.getTextContent();
            fullText += content.items.map(item => item.str).join(' ') + '\n';
          }
          pdfText = fullText;
          alert("ğŸ“„ ×”×§×•×‘×¥ × ×˜×¢×Ÿ ×‘×”×¦×œ×—×”!");
        };
        reader.readAsArrayBuffer(file);
      }
    });

    async function askAgent() {
      const input = document.getElementById("userInput").value.trim();
      if (!input) {
        alert("×”×–×Ÿ ×©××œ×” ×›×“×™ ×œ×©×œ×•×—.");
        return;
      }

      const fullPrompt = `×× ×™ ×¡×•×›×Ÿ AI ××•××—×” ×œ×¢×¡×§×™×, ××©×¤×˜×™×, ×¤×™× × ×¡×™× ×•×—×•×§ ×‘××¨×”\"×‘. × ×ª×— ××ª ×”×©××œ×” ×”×‘××” ×‘×”×ª×× ×œ×ª×•×›×Ÿ ×”×‘× ××”×§×•×‘×¥:\n${pdfText}\n\n×©××œ×”:\n${input}`;
      document.getElementById("response").textContent = "â³ ×˜×•×¢×Ÿ ×ª×©×•×‘×”...";

      try {
        const response = await fetch("https://api.openai.com/v1/chat/completions", {
          method: "POST",
          headers: {
            "Content-Type": "application/json",
            "Authorization": "Bearer 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"
          },
          body: JSON.stringify({
            model: "gpt-3.5-turbo",
            messages: [{ role: "user", content: fullPrompt }],
            temperature: 0.7
          }),
        });

        const data = await response.json();
        const answer = data.choices?.[0]?.message?.content || "âš ï¸ ×œ× ×”×ª×§×‘×œ×” ×ª×©×•×‘×” ×ª×§×™× ×”.";
        document.getElementById("response").textContent = answer;

        const speech = new SpeechSynthesisUtterance(answer);
        speech.lang = /[\u0590-\u05FF]/.test(answer) ? 'he-IL' : 'en-US';
        speechSynthesis.speak(speech);
      } catch (error) {
        document.getElementById("response").textContent = "âš ï¸ ×©×’×™××”: " + error.message;
      }
    }

    const recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
    recognition.continuous = false;
    recognition.interimResults = false;
    recognition.lang = 'he-IL';

    const recordButton = document.getElementById('recordButton');
    function startListening() {
      isRecording = true;
      recordButton.classList.add('recording');
      recognition.start();
    }

    function stopListening() {
      if (isRecording) {
        recognition.stop();
        recordButton.classList.remove('recording');
        isRecording = false;
      }
    }

    recordButton.addEventListener('mousedown', startListening);
    recordButton.addEventListener('mouseup', stopListening);
    recordButton.addEventListener('touchstart', startListening);
    recordButton.addEventListener('touchend', stopListening);

    recognition.onresult = (e) => {
      const transcript = e.results[0][0].transcript;
      document.getElementById('userInput').value = transcript;
      askAgent();
    };

    recognition.onerror = (e) => {
      document.getElementById("response").textContent = "âš ï¸ ×©×’×™××ª ×§×•×œ: " + e.error;
    };
  </script>
</body>
</html>
